{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('16P.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     59999\n",
       "unique       16\n",
       "top        ESFP\n",
       "freq       3769\n",
       "Name: Personality, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Personality'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response Id</th>\n",
       "      <th>You regularly make new friends.</th>\n",
       "      <th>You spend a lot of your free time exploring various random topics that pique your interest</th>\n",
       "      <th>Seeing other people cry can easily make you feel like you want to cry too</th>\n",
       "      <th>You often make a backup plan for a backup plan.</th>\n",
       "      <th>You usually stay calm, even under a lot of pressure</th>\n",
       "      <th>At social events, you rarely try to introduce yourself to new people and mostly talk to the ones you already know</th>\n",
       "      <th>You prefer to completely finish one project before starting another.</th>\n",
       "      <th>You are very sentimental.</th>\n",
       "      <th>You like to use organizing tools like schedules and lists.</th>\n",
       "      <th>...</th>\n",
       "      <th>You believe that pondering abstract philosophical questions is a waste of time.</th>\n",
       "      <th>You feel more drawn to places with busy, bustling atmospheres than quiet, intimate places.</th>\n",
       "      <th>You know at first glance how someone is feeling.</th>\n",
       "      <th>You often feel overwhelmed.</th>\n",
       "      <th>You complete things methodically without skipping over any steps.</th>\n",
       "      <th>You are very intrigued by things labeled as controversial.</th>\n",
       "      <th>You would pass along a good opportunity if you thought someone else needed it more.</th>\n",
       "      <th>You struggle with deadlines.</th>\n",
       "      <th>You feel confident that things will work out for you.</th>\n",
       "      <th>Personality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Response Id, You regularly make new friends., You spend a lot of your free time exploring various random topics that pique your interest, Seeing other people cry can easily make you feel like you want to cry too, You often make a backup plan for a backup plan., You usually stay calm, even under a lot of pressure, At social events, you rarely try to introduce yourself to new people and mostly talk to the ones you already know, You prefer to completely finish one project before starting another., You are very sentimental., You like to use organizing tools like schedules and lists., Even a small mistake can cause you to doubt your overall abilities and knowledge., You feel comfortable just walking up to someone you find interesting and striking up a conversation., You are not too interested in discussing various interpretations and analyses of creative works., You are more inclined to follow your head than your heart., You usually prefer just doing what you feel like at any given moment instead of planning a particular daily routine., You rarely worry about whether you make a good impression on people you meet., You enjoy participating in group activities., You like books and movies that make you come up with your own interpretation of the ending., Your happiness comes more from helping others accomplish things than your own accomplishments., You are interested in so many things that you find it difficult to choose what to try next., You are prone to worrying that things will take a turn for the worse., You avoid leadership roles in group settings., You are definitely not an artistic type of person., You think the world would be a better place if people relied more on rationality and less on their feelings., You prefer to do your chores before allowing yourself to relax., You enjoy watching people argue., You tend to avoid drawing attention to yourself., Your mood can change very quickly., You lose patience with people who are not as efficient as you., You often end up doing things at the last possible moment., You have always been fascinated by the question of what, if anything, happens after death., You usually prefer to be around others rather than on your own., You become bored or lose interest when the discussion gets highly theoretical., You find it easy to empathize with a person whose experiences are very different from yours., You usually postpone finalizing decisions for as long as possible., You rarely second-guess the choices that you have made., After a long and exhausting week, a lively social event is just what you need., You enjoy going to art museums., You often have a hard time understanding other people’s feelings., You like to have a to-do list for each day., You rarely feel insecure., You avoid making phone calls., You often spend a lot of time trying to understand views that are very different from your own., In your social circle, you are often the one who contacts your friends and initiates activities., If your plans are interrupted, your top priority is to get back on track as soon as possible., You are still bothered by mistakes that you made a long time ago., You rarely contemplate the reasons for human existence or the meaning of life., Your emotions control you more than you control them., You take great care not to make people look bad, even when it is completely their fault., Your personal work style is closer to spontaneous bursts of energy than organized and consistent efforts., When someone thinks highly of you, you wonder how long it will take them to feel disappointed in you., You would love a job that requires you to work alone most of the time., You believe that pondering abstract philosophical questions is a waste of time., You feel more drawn to places with busy, bustling atmospheres than quiet, intimate places., You know at first glance how someone is feeling., You often feel overwhelmed., You complete things methodically without skipping over any steps., You are very intrigued by things labeled as controversial., You would pass along a good opportunity if you thought someone else needed it more., You struggle with deadlines., You feel confident that things will work out for you., Personality]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 62 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = { \n",
    "    \t\"ESTJ\" : 0,\n",
    "\t    \"ENTJ\" : 1,\n",
    "\t    \"ESFJ\" : 2,\n",
    "\t    \"ENFJ\" : 3,\n",
    "\t    \"ISTJ\" : 4,\n",
    "    \t\"ISFJ\" : 5,\n",
    "\t    \"INTJ\" : 6,\n",
    "\t    \"INFJ\" : 7,\n",
    "\t    \"ESTP\" : 8,\n",
    "\t    \"ESFP\" : 9,\n",
    "\t    \"ENTP\" : 10,\n",
    "\t    \"ENFP\" : 11,\n",
    "\t    \"ISTP\" : 12,\n",
    "\t    \"ISFP\" : 13,\n",
    "\t    \"INTP\" : 14,\n",
    "\t    \"INFP\" : 15\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=['Response Id', \"Personality\"])\n",
    "y = df[\"Personality\"]\n",
    "y = y.map(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        11\n",
       "1        13\n",
       "2         7\n",
       "3        12\n",
       "4         3\n",
       "         ..\n",
       "59994     7\n",
       "59995     8\n",
       "59996    12\n",
       "59997     4\n",
       "59998     7\n",
       "Name: Personality, Length: 59999, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np_utils.to_categorical(y, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "input_size = 60\n",
    "hidden_neurons = 100\n",
    "hidden_neurons_2 = 60\n",
    "output_size = 16\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(output_size, input_dim = input_size),\n",
    "    Activation('LeakyReLU'),\n",
    "    Dense(hidden_neurons_2),\n",
    "    Activation(\"LeakyReLU\"),\n",
    "    Dense(output_size),\n",
    "    Activation(\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              metrics = ['accuracy'], optimizer = 'sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "900/900 [==============================] - 1s 603us/step - loss: 1.7170 - accuracy: 0.4966 - val_loss: 0.9236 - val_accuracy: 0.7488\n",
      "Epoch 2/100\n",
      "900/900 [==============================] - 0s 490us/step - loss: 0.6975 - accuracy: 0.8055 - val_loss: 0.5458 - val_accuracy: 0.8467\n",
      "Epoch 3/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.4874 - accuracy: 0.8650 - val_loss: 0.4346 - val_accuracy: 0.8826\n",
      "Epoch 4/100\n",
      "900/900 [==============================] - 0s 481us/step - loss: 0.4115 - accuracy: 0.8898 - val_loss: 0.3893 - val_accuracy: 0.8985\n",
      "Epoch 5/100\n",
      "900/900 [==============================] - 0s 474us/step - loss: 0.3740 - accuracy: 0.9008 - val_loss: 0.3614 - val_accuracy: 0.9066\n",
      "Epoch 6/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.3504 - accuracy: 0.9096 - val_loss: 0.3430 - val_accuracy: 0.9119\n",
      "Epoch 7/100\n",
      "900/900 [==============================] - 0s 477us/step - loss: 0.3334 - accuracy: 0.9149 - val_loss: 0.3315 - val_accuracy: 0.9156\n",
      "Epoch 8/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.3203 - accuracy: 0.9203 - val_loss: 0.3201 - val_accuracy: 0.9195\n",
      "Epoch 9/100\n",
      "900/900 [==============================] - 0s 467us/step - loss: 0.3089 - accuracy: 0.9228 - val_loss: 0.3100 - val_accuracy: 0.9241\n",
      "Epoch 10/100\n",
      "900/900 [==============================] - 0s 477us/step - loss: 0.2991 - accuracy: 0.9262 - val_loss: 0.3012 - val_accuracy: 0.9264\n",
      "Epoch 11/100\n",
      "900/900 [==============================] - 0s 476us/step - loss: 0.2902 - accuracy: 0.9296 - val_loss: 0.2941 - val_accuracy: 0.9296\n",
      "Epoch 12/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.2821 - accuracy: 0.9333 - val_loss: 0.2880 - val_accuracy: 0.9317\n",
      "Epoch 13/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.2748 - accuracy: 0.9352 - val_loss: 0.2808 - val_accuracy: 0.9348\n",
      "Epoch 14/100\n",
      "900/900 [==============================] - 0s 465us/step - loss: 0.2682 - accuracy: 0.9372 - val_loss: 0.2752 - val_accuracy: 0.9368\n",
      "Epoch 15/100\n",
      "900/900 [==============================] - 0s 466us/step - loss: 0.2622 - accuracy: 0.9397 - val_loss: 0.2713 - val_accuracy: 0.9377\n",
      "Epoch 16/100\n",
      "900/900 [==============================] - 0s 474us/step - loss: 0.2565 - accuracy: 0.9413 - val_loss: 0.2663 - val_accuracy: 0.9397\n",
      "Epoch 17/100\n",
      "900/900 [==============================] - 0s 466us/step - loss: 0.2518 - accuracy: 0.9435 - val_loss: 0.2618 - val_accuracy: 0.9416\n",
      "Epoch 18/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.2471 - accuracy: 0.9452 - val_loss: 0.2584 - val_accuracy: 0.9437\n",
      "Epoch 19/100\n",
      "900/900 [==============================] - 0s 463us/step - loss: 0.2430 - accuracy: 0.9469 - val_loss: 0.2538 - val_accuracy: 0.9448\n",
      "Epoch 20/100\n",
      "900/900 [==============================] - 0s 473us/step - loss: 0.2391 - accuracy: 0.9475 - val_loss: 0.2510 - val_accuracy: 0.9459\n",
      "Epoch 21/100\n",
      "900/900 [==============================] - 0s 476us/step - loss: 0.2357 - accuracy: 0.9489 - val_loss: 0.2480 - val_accuracy: 0.9468\n",
      "Epoch 22/100\n",
      "900/900 [==============================] - 0s 509us/step - loss: 0.2323 - accuracy: 0.9502 - val_loss: 0.2465 - val_accuracy: 0.9473\n",
      "Epoch 23/100\n",
      "900/900 [==============================] - 0s 476us/step - loss: 0.2293 - accuracy: 0.9510 - val_loss: 0.2421 - val_accuracy: 0.9488\n",
      "Epoch 24/100\n",
      "900/900 [==============================] - 0s 520us/step - loss: 0.2266 - accuracy: 0.9519 - val_loss: 0.2405 - val_accuracy: 0.9491\n",
      "Epoch 25/100\n",
      "900/900 [==============================] - 0s 552us/step - loss: 0.2238 - accuracy: 0.9528 - val_loss: 0.2393 - val_accuracy: 0.9493\n",
      "Epoch 26/100\n",
      "900/900 [==============================] - 0s 506us/step - loss: 0.2215 - accuracy: 0.9533 - val_loss: 0.2363 - val_accuracy: 0.9511\n",
      "Epoch 27/100\n",
      "900/900 [==============================] - 0s 457us/step - loss: 0.2192 - accuracy: 0.9543 - val_loss: 0.2355 - val_accuracy: 0.9505\n",
      "Epoch 28/100\n",
      "900/900 [==============================] - 0s 460us/step - loss: 0.2173 - accuracy: 0.9550 - val_loss: 0.2329 - val_accuracy: 0.9519\n",
      "Epoch 29/100\n",
      "900/900 [==============================] - 0s 458us/step - loss: 0.2151 - accuracy: 0.9560 - val_loss: 0.2314 - val_accuracy: 0.9521\n",
      "Epoch 30/100\n",
      "900/900 [==============================] - 0s 473us/step - loss: 0.2132 - accuracy: 0.9563 - val_loss: 0.2307 - val_accuracy: 0.9531\n",
      "Epoch 31/100\n",
      "900/900 [==============================] - 0s 459us/step - loss: 0.2113 - accuracy: 0.9569 - val_loss: 0.2285 - val_accuracy: 0.9537\n",
      "Epoch 32/100\n",
      "900/900 [==============================] - 0s 456us/step - loss: 0.2097 - accuracy: 0.9573 - val_loss: 0.2267 - val_accuracy: 0.9537\n",
      "Epoch 33/100\n",
      "900/900 [==============================] - 0s 456us/step - loss: 0.2078 - accuracy: 0.9584 - val_loss: 0.2263 - val_accuracy: 0.9539\n",
      "Epoch 34/100\n",
      "900/900 [==============================] - 0s 476us/step - loss: 0.2063 - accuracy: 0.9579 - val_loss: 0.2252 - val_accuracy: 0.9551\n",
      "Epoch 35/100\n",
      "900/900 [==============================] - 0s 463us/step - loss: 0.2047 - accuracy: 0.9582 - val_loss: 0.2234 - val_accuracy: 0.9552\n",
      "Epoch 36/100\n",
      "900/900 [==============================] - 0s 460us/step - loss: 0.2035 - accuracy: 0.9589 - val_loss: 0.2229 - val_accuracy: 0.9551\n",
      "Epoch 37/100\n",
      "900/900 [==============================] - 0s 459us/step - loss: 0.2018 - accuracy: 0.9595 - val_loss: 0.2208 - val_accuracy: 0.9550\n",
      "Epoch 38/100\n",
      "900/900 [==============================] - 0s 458us/step - loss: 0.2005 - accuracy: 0.9598 - val_loss: 0.2198 - val_accuracy: 0.9556\n",
      "Epoch 39/100\n",
      "900/900 [==============================] - 0s 460us/step - loss: 0.1993 - accuracy: 0.9601 - val_loss: 0.2186 - val_accuracy: 0.9560\n",
      "Epoch 40/100\n",
      "900/900 [==============================] - 0s 461us/step - loss: 0.1981 - accuracy: 0.9606 - val_loss: 0.2190 - val_accuracy: 0.9559\n",
      "Epoch 41/100\n",
      "900/900 [==============================] - 0s 462us/step - loss: 0.1969 - accuracy: 0.9612 - val_loss: 0.2170 - val_accuracy: 0.9567\n",
      "Epoch 42/100\n",
      "900/900 [==============================] - 0s 462us/step - loss: 0.1957 - accuracy: 0.9614 - val_loss: 0.2166 - val_accuracy: 0.9569\n",
      "Epoch 43/100\n",
      "900/900 [==============================] - 0s 466us/step - loss: 0.1946 - accuracy: 0.9617 - val_loss: 0.2159 - val_accuracy: 0.9573\n",
      "Epoch 44/100\n",
      "900/900 [==============================] - 0s 466us/step - loss: 0.1935 - accuracy: 0.9623 - val_loss: 0.2154 - val_accuracy: 0.9573\n",
      "Epoch 45/100\n",
      "900/900 [==============================] - 0s 481us/step - loss: 0.1922 - accuracy: 0.9622 - val_loss: 0.2148 - val_accuracy: 0.9579\n",
      "Epoch 46/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.1915 - accuracy: 0.9628 - val_loss: 0.2132 - val_accuracy: 0.9582\n",
      "Epoch 47/100\n",
      "900/900 [==============================] - 0s 494us/step - loss: 0.1904 - accuracy: 0.9632 - val_loss: 0.2128 - val_accuracy: 0.9591\n",
      "Epoch 48/100\n",
      "900/900 [==============================] - 0s 509us/step - loss: 0.1896 - accuracy: 0.9630 - val_loss: 0.2129 - val_accuracy: 0.9581\n",
      "Epoch 49/100\n",
      "900/900 [==============================] - 0s 476us/step - loss: 0.1888 - accuracy: 0.9633 - val_loss: 0.2115 - val_accuracy: 0.9588\n",
      "Epoch 50/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.1876 - accuracy: 0.9643 - val_loss: 0.2103 - val_accuracy: 0.9597\n",
      "Epoch 51/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.1869 - accuracy: 0.9647 - val_loss: 0.2100 - val_accuracy: 0.9597\n",
      "Epoch 52/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.1860 - accuracy: 0.9651 - val_loss: 0.2094 - val_accuracy: 0.9591\n",
      "Epoch 53/100\n",
      "900/900 [==============================] - 0s 489us/step - loss: 0.1852 - accuracy: 0.9650 - val_loss: 0.2078 - val_accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.1844 - accuracy: 0.9650 - val_loss: 0.2080 - val_accuracy: 0.9601\n",
      "Epoch 55/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.1835 - accuracy: 0.9657 - val_loss: 0.2076 - val_accuracy: 0.9605\n",
      "Epoch 56/100\n",
      "900/900 [==============================] - 0s 474us/step - loss: 0.1826 - accuracy: 0.9658 - val_loss: 0.2064 - val_accuracy: 0.9601\n",
      "Epoch 57/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.1819 - accuracy: 0.9661 - val_loss: 0.2065 - val_accuracy: 0.9601\n",
      "Epoch 58/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.1812 - accuracy: 0.9659 - val_loss: 0.2057 - val_accuracy: 0.9605\n",
      "Epoch 59/100\n",
      "900/900 [==============================] - 0s 481us/step - loss: 0.1804 - accuracy: 0.9662 - val_loss: 0.2057 - val_accuracy: 0.9609\n",
      "Epoch 60/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.1797 - accuracy: 0.9667 - val_loss: 0.2054 - val_accuracy: 0.9606\n",
      "Epoch 61/100\n",
      "900/900 [==============================] - 0s 471us/step - loss: 0.1789 - accuracy: 0.9672 - val_loss: 0.2045 - val_accuracy: 0.9606\n",
      "Epoch 62/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.1785 - accuracy: 0.9670 - val_loss: 0.2036 - val_accuracy: 0.9607\n",
      "Epoch 63/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.1776 - accuracy: 0.9673 - val_loss: 0.2034 - val_accuracy: 0.9612\n",
      "Epoch 64/100\n",
      "900/900 [==============================] - 0s 482us/step - loss: 0.1770 - accuracy: 0.9674 - val_loss: 0.2029 - val_accuracy: 0.9615\n",
      "Epoch 65/100\n",
      "900/900 [==============================] - 0s 472us/step - loss: 0.1765 - accuracy: 0.9675 - val_loss: 0.2026 - val_accuracy: 0.9609\n",
      "Epoch 66/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.1757 - accuracy: 0.9682 - val_loss: 0.2022 - val_accuracy: 0.9617\n",
      "Epoch 67/100\n",
      "900/900 [==============================] - 0s 467us/step - loss: 0.1752 - accuracy: 0.9681 - val_loss: 0.2017 - val_accuracy: 0.9621\n",
      "Epoch 68/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.1746 - accuracy: 0.9684 - val_loss: 0.2012 - val_accuracy: 0.9619\n",
      "Epoch 69/100\n",
      "900/900 [==============================] - 0s 471us/step - loss: 0.1740 - accuracy: 0.9684 - val_loss: 0.2005 - val_accuracy: 0.9616\n",
      "Epoch 70/100\n",
      "900/900 [==============================] - 0s 478us/step - loss: 0.1735 - accuracy: 0.9687 - val_loss: 0.2007 - val_accuracy: 0.9617\n",
      "Epoch 71/100\n",
      "900/900 [==============================] - 0s 467us/step - loss: 0.1730 - accuracy: 0.9690 - val_loss: 0.1998 - val_accuracy: 0.9622\n",
      "Epoch 72/100\n",
      "900/900 [==============================] - 0s 501us/step - loss: 0.1724 - accuracy: 0.9690 - val_loss: 0.2007 - val_accuracy: 0.9617\n",
      "Epoch 73/100\n",
      "900/900 [==============================] - 0s 473us/step - loss: 0.1718 - accuracy: 0.9691 - val_loss: 0.2002 - val_accuracy: 0.9625\n",
      "Epoch 74/100\n",
      "900/900 [==============================] - 0s 510us/step - loss: 0.1712 - accuracy: 0.9700 - val_loss: 0.1990 - val_accuracy: 0.9627\n",
      "Epoch 75/100\n",
      "900/900 [==============================] - 0s 475us/step - loss: 0.1707 - accuracy: 0.9698 - val_loss: 0.1991 - val_accuracy: 0.9623\n",
      "Epoch 76/100\n",
      "900/900 [==============================] - 0s 475us/step - loss: 0.1703 - accuracy: 0.9698 - val_loss: 0.1987 - val_accuracy: 0.9625\n",
      "Epoch 77/100\n",
      "900/900 [==============================] - 0s 482us/step - loss: 0.1698 - accuracy: 0.9698 - val_loss: 0.1974 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "900/900 [==============================] - 0s 477us/step - loss: 0.1694 - accuracy: 0.9700 - val_loss: 0.1985 - val_accuracy: 0.9638\n",
      "Epoch 79/100\n",
      "900/900 [==============================] - 0s 496us/step - loss: 0.1688 - accuracy: 0.9703 - val_loss: 0.1978 - val_accuracy: 0.9637\n",
      "Epoch 80/100\n",
      "900/900 [==============================] - 0s 473us/step - loss: 0.1683 - accuracy: 0.9704 - val_loss: 0.1979 - val_accuracy: 0.9626\n",
      "Epoch 81/100\n",
      "900/900 [==============================] - 0s 473us/step - loss: 0.1678 - accuracy: 0.9706 - val_loss: 0.1968 - val_accuracy: 0.9640\n",
      "Epoch 82/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.1674 - accuracy: 0.9705 - val_loss: 0.1971 - val_accuracy: 0.9642\n",
      "Epoch 83/100\n",
      "900/900 [==============================] - 0s 467us/step - loss: 0.1670 - accuracy: 0.9704 - val_loss: 0.1959 - val_accuracy: 0.9643\n",
      "Epoch 84/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.1664 - accuracy: 0.9707 - val_loss: 0.1959 - val_accuracy: 0.9636\n",
      "Epoch 85/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.1661 - accuracy: 0.9710 - val_loss: 0.1960 - val_accuracy: 0.9645\n",
      "Epoch 86/100\n",
      "900/900 [==============================] - 0s 467us/step - loss: 0.1655 - accuracy: 0.9712 - val_loss: 0.1950 - val_accuracy: 0.9647\n",
      "Epoch 87/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.1652 - accuracy: 0.9709 - val_loss: 0.1950 - val_accuracy: 0.9644\n",
      "Epoch 88/100\n",
      "900/900 [==============================] - 0s 467us/step - loss: 0.1649 - accuracy: 0.9711 - val_loss: 0.1953 - val_accuracy: 0.9647\n",
      "Epoch 89/100\n",
      "900/900 [==============================] - 0s 468us/step - loss: 0.1644 - accuracy: 0.9714 - val_loss: 0.1948 - val_accuracy: 0.9648\n",
      "Epoch 90/100\n",
      "900/900 [==============================] - 0s 469us/step - loss: 0.1640 - accuracy: 0.9714 - val_loss: 0.1942 - val_accuracy: 0.9647\n",
      "Epoch 91/100\n",
      "900/900 [==============================] - 0s 471us/step - loss: 0.1636 - accuracy: 0.9716 - val_loss: 0.1937 - val_accuracy: 0.9653\n",
      "Epoch 92/100\n",
      "900/900 [==============================] - 0s 470us/step - loss: 0.1633 - accuracy: 0.9721 - val_loss: 0.1934 - val_accuracy: 0.9653\n",
      "Epoch 93/100\n",
      "900/900 [==============================] - 0s 476us/step - loss: 0.1629 - accuracy: 0.9719 - val_loss: 0.1935 - val_accuracy: 0.9651\n",
      "Epoch 94/100\n",
      "900/900 [==============================] - 0s 495us/step - loss: 0.1626 - accuracy: 0.9718 - val_loss: 0.1927 - val_accuracy: 0.9649\n",
      "Epoch 95/100\n",
      "900/900 [==============================] - 0s 479us/step - loss: 0.1622 - accuracy: 0.9724 - val_loss: 0.1931 - val_accuracy: 0.9655\n",
      "Epoch 96/100\n",
      "900/900 [==============================] - 0s 467us/step - loss: 0.1619 - accuracy: 0.9726 - val_loss: 0.1926 - val_accuracy: 0.9651\n",
      "Epoch 97/100\n",
      "900/900 [==============================] - 0s 471us/step - loss: 0.1616 - accuracy: 0.9720 - val_loss: 0.1933 - val_accuracy: 0.9650\n",
      "Epoch 98/100\n",
      "900/900 [==============================] - 0s 474us/step - loss: 0.1613 - accuracy: 0.9722 - val_loss: 0.1924 - val_accuracy: 0.9660\n",
      "Epoch 99/100\n",
      "900/900 [==============================] - 0s 507us/step - loss: 0.1609 - accuracy: 0.9724 - val_loss: 0.1920 - val_accuracy: 0.9651\n",
      "Epoch 100/100\n",
      "900/900 [==============================] - 0s 477us/step - loss: 0.1604 - accuracy: 0.9729 - val_loss: 0.1916 - val_accuracy: 0.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2855abfd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs= 100, batch_size=50,  verbose=1, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
